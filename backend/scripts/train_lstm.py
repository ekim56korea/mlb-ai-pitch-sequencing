import duckdb
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import LabelEncoder, StandardScaler
import joblib
import os
import sys

# ğŸŒŸ [í•µì‹¬ ìˆ˜ì • 1] ìƒìœ„ í´ë”(í”„ë¡œì íŠ¸ ë£¨íŠ¸)ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€
# ì´ë ‡ê²Œ í•´ì•¼ 'app' í´ë” ì•ˆì— ìˆëŠ” model.pyë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from app.model import PitchLSTM  # âœ… ì´ì œ app íŒ¨í‚¤ì§€ ì•ˆì—ì„œ ì°¾ìŠµë‹ˆë‹¤.

# â”€â”€â”€ ì„¤ì • ë° ê²½ë¡œ ìˆ˜ì • â”€â”€â”€
# ğŸŒŸ [í•µì‹¬ ìˆ˜ì • 2] ë°ì´í„°ê°€ 'data' í´ë”ì— ìˆìœ¼ë¯€ë¡œ ê²½ë¡œë¥¼ ëª…í™•íˆ ì§€ì •
DATA_DIR = os.path.join(parent_dir, "data")
DB_FILE = os.path.join(DATA_DIR, "savant.duckdb")
MODEL_PATH = os.path.join(DATA_DIR, "pitch_lstm.pth")
ENCODER_PATH = os.path.join(DATA_DIR, "encoders.pkl")

SEQ_LENGTH = 5  
BATCH_SIZE = 64
EPOCHS = 10     # í•™ìŠµ íšŸìˆ˜ ì¡°ê¸ˆ ëŠ˜ë¦¼
LEARNING_RATE = 0.001

# â”€â”€â”€ 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ â”€â”€â”€
def load_data():
    if not os.path.exists(DB_FILE):
        print(f"âŒ Database not found at: {DB_FILE}")
        print("   Please run 'python scripts/setup_db.py' first.")
        sys.exit(1)

    print(f"ğŸ¦† Connecting to DuckDB at {DB_FILE}...")
    con = duckdb.connect(DB_FILE, read_only=True)
    
    # ìµœê·¼ 3ë…„ì¹˜ ë°ì´í„° ì¡°íšŒ
    query = """
        SELECT game_pk, at_bat_number, pitch_number, 
               pitch_type, release_speed, plate_x, plate_z, 
               balls, strikes, stand
        FROM pitches
        WHERE game_date >= '2022-01-01'
          AND pitch_type IS NOT NULL 
          AND release_speed IS NOT NULL
          AND plate_x IS NOT NULL
        ORDER BY game_pk, at_bat_number, pitch_number
    """
    print("ğŸ“Š Executing Query...")
    df = con.execute(query).df()
    con.close()
    
    print(f"âœ… Loaded {len(df):,} pitches.")
    return df

# â”€â”€â”€ 2. ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± (Dataset) â”€â”€â”€
class PitchDataset(Dataset):
    def __init__(self, sequences, labels):
        self.sequences = torch.FloatTensor(sequences)
        self.labels = torch.LongTensor(labels)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return self.sequences[idx], self.labels[idx]

def create_sequences(df, le_pitch, le_stand):
    # ì¸ì½”ë”©
    df['pitch_code'] = le_pitch.fit_transform(df['pitch_type'])
    df['stand_code'] = le_stand.fit_transform(df['stand'])
    
    # ì •ê·œí™”
    scaler = StandardScaler()
    features = ['release_speed', 'plate_x', 'plate_z', 'balls', 'strikes', 'stand_code']
    df[features] = scaler.fit_transform(df[features])
    
    data = df[features + ['pitch_code']].values
    
    X, y = [], []
    
    print("âœ‚ï¸ Creating sequences...")
    # ê°„ë‹¨í•œ ì‹œí€€ìŠ¤ ìƒì„± (ì—°ì†ëœ ë°ì´í„° ê°€ì •)
    # ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡±í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœëŒ€ 10ë§Œê°œ ìƒ˜í”Œë§í•˜ê±°ë‚˜ ëŠì–´ì„œ ì²˜ë¦¬
    limit = min(len(data), 200000) # ë°ëª¨ìš©ìœ¼ë¡œ 20ë§Œê°œë§Œ ì‚¬ìš© (ì†ë„ í–¥ìƒ)
    
    for i in range(limit - SEQ_LENGTH):
        seq_features = data[i : i + SEQ_LENGTH, :-1] # (5, 6)
        target = data[i + SEQ_LENGTH, -1] # ë‹¤ìŒ ê³µ
        
        X.append(seq_features)
        y.append(target)
        
    return np.array(X), np.array(y), scaler

# â”€â”€â”€ 3. ë©”ì¸ í•™ìŠµ ë£¨í”„ â”€â”€â”€
def train():
    df = load_data()
    
    if df.empty:
        print("âŒ No data found. Check your database.")
        return

    le_pitch = LabelEncoder()
    le_stand = LabelEncoder()
    
    X, y, scaler = create_sequences(df, le_pitch, le_stand)
    
    if len(X) == 0:
        print("âŒ Not enough data to create sequences.")
        return

    dataset = PitchDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    input_size = X.shape[2]
    num_classes = len(le_pitch.classes_)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ’» Training on {device}")
    
    model = PitchLSTM(input_size, 128, 2, num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    
    print("ğŸ”¥ Start Training...")
    model.train()
    for epoch in range(EPOCHS):
        total_loss = 0
        for i, (seqs, labels) in enumerate(dataloader):
            seqs, labels = seqs.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(seqs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
        print(f"Epoch [{epoch+1}/{EPOCHS}], Loss: {total_loss/len(dataloader):.4f}")
        
    # ì €ì¥
    print(f"ğŸ’¾ Saving Model to {MODEL_PATH}...")
    torch.save(model.state_dict(), MODEL_PATH)
    
    meta_data = {
        'le_pitch': le_pitch,
        'le_stand': le_stand,
        'scaler': scaler,
        'input_size': input_size,
        'num_classes': num_classes
    }
    joblib.dump(meta_data, ENCODER_PATH)
    print("ğŸ‰ Training Complete!")

if __name__ == "__main__":
    train()