from pybaseball import playerid_lookup, statcast_pitcher, statcast_batter
import pandas as pd
import sqlite3
import os
import asyncio
from datetime import datetime, timedelta
from api.engine.preprocessor import DataPreprocessor

class PlayerDataLoader:
    """
    [v7.0 Phase 1] Optimized Data Loader (Zero-Cost Architecture)
    - SQLite WAL Mode & Indexing (Performance Tuning)
    - Parquet File Caching (Cold Data Storage)
    - Async IO Support
    """
    def __init__(self, db_path="data/mlb_statcast.db", parquet_dir="data/parquet_cache"):
        self.db_path = db_path
        self.parquet_dir = parquet_dir
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        os.makedirs(self.parquet_dir, exist_ok=True)
        
        self.preprocessor = DataPreprocessor()
        
        # [1.1] DB ìµœì í™” (WAL ëª¨ë“œ ë° ì¸ë±ì‹±)
        self._init_db_optimization()

    def _init_db_optimization(self):
        """SQLite ì„±ëŠ¥ì„ ê·¹í•œìœ¼ë¡œ ëŒì–´ì˜¬ë¦¬ëŠ” ì„¤ì •"""
        try:
            conn = sqlite3.connect(self.db_path)
            # WAL(Write-Ahead Logging) ëª¨ë“œ: ì½ê¸°/ì“°ê¸° ë™ì‹œì„± í–¥ìƒ
            conn.execute("PRAGMA journal_mode=WAL;")
            # ë™ê¸°í™” ë ˆë²¨ ì™„í™” (ë°ì´í„° ì•ˆì •ì„±ë³´ë‹¤ ì†ë„ ìš°ì„ )
            conn.execute("PRAGMA synchronous=NORMAL;")
            # ìºì‹œ ì‚¬ì´ì¦ˆ ì¦ëŒ€
            conn.execute("PRAGMA cache_size=10000;")
            
            # [Indexing] ìì£¼ ì¡°íšŒí•˜ëŠ” ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ìƒì„±
            conn.execute("CREATE INDEX IF NOT EXISTS idx_pitcher_date ON pitcher_cache (pitcher, game_date);")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_batter_date ON batter_cache (batter, game_date);")
            
            conn.close()
            print("âš¡ SQLite WAL Mode & Indexing Enabled.")
        except Exception as e:
            print(f"âš ï¸ DB Optimization Warning: {e}")

    def find_player_id(self, name_input):
        """(ê¸°ì¡´ê³¼ ë™ì¼) ìœ ì—°í•œ ì„ ìˆ˜ ê²€ìƒ‰"""
        if not name_input: return None
        parts = name_input.strip().split()
        if not parts: return None

        try:
            data = pd.DataFrame()
            if len(parts) >= 2:
                last, first = parts[-1], parts[0]
                data = playerid_lookup(last, first)
                if data.empty: data = playerid_lookup(first, last)
                if data.empty: data = playerid_lookup(parts[-1], parts[0], fuzzy=True)
            else:
                data = playerid_lookup(parts[0], fuzzy=True)

            if data.empty:
                print(f"âŒ Player not found: '{name_input}'")
                return None
            
            if 'mlb_played_last' in data.columns:
                data = data.sort_values('mlb_played_last', ascending=False)
            
            player_id = data.iloc[0]['key_mlbam']
            print(f"âœ… Found Player: {data.iloc[0]['name_first']} {data.iloc[0]['name_last']} (ID: {player_id})")
            return player_id
            
        except Exception as e:
            print(f"âŒ Lookup Error: {e}")
            return None

    def load_pitcher_data(self, player_id, start_dt=None, end_dt=None):
        """[1.2] Parquet ìš°ì„  ë¡œë”© ë°©ì‹ ì ìš©"""
        if not start_dt: start_dt = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
        if not end_dt: end_dt = datetime.now().strftime('%Y-%m-%d')

        # 1. Parquet ìºì‹œ í™•ì¸ (ê°€ì¥ ë¹ ë¦„)
        parquet_path = os.path.join(self.parquet_dir, f"pitcher_{player_id}.parquet")
        if os.path.exists(parquet_path):
            try:
                # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸ (í•˜ë£¨ ì§€ë‚¬ìœ¼ë©´ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ)
                mtime = datetime.fromtimestamp(os.path.getmtime(parquet_path))
                if datetime.now() - mtime < timedelta(hours=24):
                    print(f"âš¡ Loading from Parquet Cache: {parquet_path}")
                    return pd.read_parquet(parquet_path)
            except Exception: pass # ì½ê¸° ì‹¤íŒ¨ ì‹œ ë‹¤ìš´ë¡œë“œ ì§„í–‰

        print(f"ğŸ“¥ Downloading Pitcher Data (ID: {player_id})...")
        try:
            df = statcast_pitcher(start_dt, end_dt, player_id)
            if df is None or df.empty: return pd.DataFrame()
            
            df_clean = self.preprocessor.clean_data(df)
            
            # 2. ì €ì¥ (DB + Parquet)
            self._save_to_db(df_clean, "pitcher_cache")
            self._save_to_parquet(df_clean, parquet_path) # [New]
            
            return df_clean
        except Exception as e:
            print(f"âŒ Error: {e}")
            return pd.DataFrame()

    def load_batter_data(self, player_id, start_dt=None, end_dt=None):
        if not start_dt: start_dt = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
        if not end_dt: end_dt = datetime.now().strftime('%Y-%m-%d')

        parquet_path = os.path.join(self.parquet_dir, f"batter_{player_id}.parquet")
        if os.path.exists(parquet_path):
            try:
                mtime = datetime.fromtimestamp(os.path.getmtime(parquet_path))
                if datetime.now() - mtime < timedelta(hours=24):
                    print(f"âš¡ Loading from Parquet Cache: {parquet_path}")
                    return pd.read_parquet(parquet_path)
            except: pass

        print(f"ğŸ“¥ Downloading Batter Data (ID: {player_id})...")
        try:
            df = statcast_batter(start_dt, end_dt, player_id)
            if df is None or df.empty: return pd.DataFrame()
            
            self._save_to_db(df, "batter_cache")
            self._save_to_parquet(df, parquet_path)
            return df
        except Exception as e:
            print(f"âŒ Error: {e}")
            return pd.DataFrame()

    def _save_to_db(self, df, table_name):
        """SQLite ì €ì¥ (ë©”íƒ€ë°ì´í„° ë° SQL ì¿¼ë¦¬ìš©)"""
        try:
            conn = sqlite3.connect(self.db_path)
            cols = ['game_date', 'player_name', 'batter', 'pitcher', 'events', 
                    'description', 'zone', 'stand', 'p_throws', 'pitch_type', 
                    'release_speed', 'release_spin_rate', 'pfx_x', 'pfx_z', 
                    'plate_x', 'plate_z', 'release_extension']
            save_cols = [c for c in cols if c in df.columns]
            df[save_cols].to_sql(table_name, conn, if_exists='replace', index=False)
            conn.close()
        except Exception as e: print(f"âš ï¸ DB Save Warning: {e}")

    def _save_to_parquet(self, df, path):
        """[1.2] Parquet ì €ì¥ (ì´ˆê³ ì† ë¡œë”©ìš©)"""
        try:
            # ëª¨ë“  ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ë©´ í˜¸í™˜ì„± ë¬¸ì œ ê°ì†Œ (ì„ íƒì‚¬í•­)
            # ì—¬ê¸°ì„œëŠ” ê·¸ëŒ€ë¡œ ì €ì¥
            df.to_parquet(path, engine='pyarrow', index=False)
            print(f"ğŸ’¾ Saved to Parquet: {path}")
        except Exception as e:
            print(f"âš ï¸ Parquet Save Warning: {e}")